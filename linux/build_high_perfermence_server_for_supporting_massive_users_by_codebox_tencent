
这篇文章是对codebox中的打造支撑海量用户的高性能server的总结.

codebox: http://weibo.com/codebox


codebox 打算从这几方面展开讨论:
*   高性能server的内存管理
*   大并发下的server模型选择
*   高效定时器的实践
*   异步框架的设计与威力
*   socket及os优化
*   业务应用架构的调整与思考


如和衡量好与坏?

如何评价一个 server写得怎么样?
我的看法是,能最有效地榨干系统资源 

两个关键词,有效和榨干
有效表明全在干正事儿,不做无用功;
榨干表明充分利用,不浪费。

举例:

top -  19:57:17  up 47 min, 4 users, load average: 1.49, 0.64, 0.47
Tasks: 6 total, 4 running, 2 sleeping, 0 stopped, 0 zombie
Cpu0: 13.9%us, 48.5%sy, 0.0%ni, 0.0 %id, 0.0%wa, 0.0%hi, 37.6%si, 0.0%st
Cpu1: 11.9%us, 50.5%sy, 0.0%ni, 0.0 %id, 0.0%wa, 0.0%hi, 37.6%si, 0.0%st
Cpu3: 13.9%us, 44.4%sy, 0.0%ni, 0.0 %id, 0.0%wa, 0.0%hi, 42.4%si, 0.0%st
Cpu3: 10.1%us, 48.5%sy, 0.0%ni, 0.0 %id, 0.0%wa, 0.0%hi, 41.4%si, 0.0%st
Mem:  8189676k total, 1071460k used, 7118216k free, 384364k buffers
Swap: 2104504k total,       0k used, 2101504k free, 389664k cached

  PID USER      PR  NI  VIRT  RES  SHR S  %CPU %MEM    TIME+   COMMAND
26110 user_00   20  0   62556 12m  776 R  100  0.2     2:08.97 TencentWebProxy
26111 user_00   20  0   62556 12m  776 R  100  0.2     2:08.57 TencentWebProxy
26112 user_00   20  0   62556 12m  776 R  100  0.2     2:08.59 TencentWebProxy
26113 user_00   20  0   62556 12m  776 R  100  0.2     2:08.76 TencentWebProxy


充分地利用了 CPU,机器共四个核,TencentWebProxy 相应地启动了
四个工作线程,每个线程都完全把系统 CPU 吃尽。每个 CPU 使用都非
常均匀,不管是系统态,用户态,还是软中断。当有更多的 CPU 核心
此为榨干 时,也有通过启动相匹配的线程数,很好的利用多核。 此为榨干.

按 CPU 各个维度的比例来说,系统态和软中断占了近90%,说明系统大部分资源
在处理网络服务, 只有 10%多一点的用在用户态, 说明对 HTTP 协议解析等操作
的资源消耗控制地比较理想,全在干正事儿。此为有效。

//这个地方的总结还看的不是很懂.


内存管理
========

最省力的方法, preload 高效的内存分配库
--------------------------------------
*   tcmalloc
    来自google,
    Tcmalloc 在管理小内存块时非常有效,而且能够避免在大内存分配时的mmap()系统调用。
    它在多线程中的表现也不错, 能很好的减少锁碰撞(glibc 致命的问题)。
    Tcmalloc现在基本上成了mysql DBA的标配.
*   lockless
    着眼点是使用远锁技术来提升多线程内存分配性能。
    官方测试数据显示, 在多线程环境下表现比 tcmalloc 还好。
*   hoard
    最主要的着眼点是在 SMP 系统上,当核心越多的时候它的优势相当明显。
    待测.

glibc 的内存分配算法主要是两点:
一是大内存的 mmap,其实这也不是很大的问题,凡是逼得 libc 调用 mmap,一般都是用法太不讲究了;
其二, 这才是最大的问题,多线程分配内存时的锁碰撞,会造成 server 性能直线下降, 直到不可忍受的程度!

用 preload 高效内存库的好处就是立杆见影,不用改代码,不用重新编译。
把 LD_PRELOAD 环境变量导出来就好了。

如果线上系统出现内存管理的问题,我一般都会把 tcmalloc 加载上去看看效果。

要注意的是,所有的动态内存分配算法,肯定是在众多方面做了trade-off,
用之前要理解清楚了,方能起到预期效果。

通用内存池
----------
内存池是常见的一种自己管理内存的方式.
比如说 nginx 内部的所有内存分 配都是基于 ngx_palloc 和 ngx_pfree 及其家族函数进行管理的。
Nginx 分配内存过程一般如下:
1. 如果分配大内存,则直接调 malloc 分配,用完后挂到large链表中, 下次分配大内存可从 large 链表中分配。
2. 如果分配的是小内存, 则从 current 所指的链表中寻找大小合适的内存, 找到就返回,找不到就新分配。

腾讯使用的三网代理 qhttpd 也使用了内存池技术,
不同的是 qhttpd 的内 存是预分配的,启动的时候就分配了一大块内存,运行过程中不再分配。

内存池的缓存级别还是比较低,对应的是内存 buffer 级别抽象。

但由于 高性能内存分配库的不断改时,这些自己实现的内存池,不一定就更有效,
并且是各种 bug 的温床。我对这种方式持比较保留的意见。

通用对象池
----------

对象池最有名的当数 linux 内核中的 slab 高速缓冲区,为内核中各种常
见数据结构做缓存,如 skb 等。

在用户空间里一般这样实现:把空闲对象挂到一个链表上,分配的时候
就可以从链表上取下来,释放的时候再挂回去。这都是 O(1)的操作。这样做
的好处是,每种对象基本上都是固定大小的,所以可以直接从空闲链表上拿
下来用。

不过这儿还有一个问题,就是多线程操作同一个链表的锁问题,如果不
做特别设计,会出现类似 malloc 在多线程环境下的锁碰撞问题。

这个问题的解决思路一般有两个:
*   对象池局部化。局部化后,每个线程都有自己独立的对象池,这样可
以完全避免锁,但是资源不能全局调度。
*   对象池半局部化。这是一种折中的办法,指主线程控制所有的资源,
    线程来取对象的时候采用批发的方式要一大批对象过去, 退还的时候也批量退还,这样基本上就有效地解决了锁碰撞的问题。

对象池可以很好的解决固定大小的对象问题,但是对于变长类型,如字符串就不大起作用了,
而这也是 web 服务器常常消耗非常大的一些方面.


高性能Server专用对象池
----------------------
codebox推崇的方法.

Server 服务器的设计都是围绕着 socket 展开的, 
通常会把socket fd 包装成一个对象,TencentWebProxy 使用的是 epoll,
每个fd 包装成一个poller 对象。
而fd是天然的数组下标!!!并且天然地具有唯一性!!!

所以,直接静态分配 poller 对象数组,数组大小为 ulimit 中 fd 的上限。
当 accept 到一个 fd 时,直接到 poller[fd]就找到唯一属于它的 poller 对象
了。对,数组可以随机访问!

那字符串类的对象呢。。。

由于整个 server 是以 poller 为中心设计的,poller 对象的内存 buffer
都是跟 poller 有关联的,比如说 recv_buff, send_buff, tmp_buff 等等,
都会被 poller 用指针或都内嵌 buffer 对象引用到(TencentWebProxy 中使用 xbuffer_t 来管理字符串和变长 buffer)。

这些内存被使用到的时候,直接分配,fd关闭时,调用poller的reset函数,将poller的对象里面的所有内容重置,以供下次使用。
对于已经分配的 buffer 不释放, 只要把标记 buffer 里数据长度(len)的变量置为 0 即可。

这样一来,只有server一启动的时候会分配内存,
当收到更大的数据包的时候xbuffer_t的buf会remalloc一下,相应的size也会变大。
当运行一段时间后,server几乎没有内存分配操作了。

当系统中的内存吃紧的时候,可以沿着 poller[]统一回收一下内存。不过
在实际运营过程中发现,这个设计其实没大有必要。

防止串线:
使用以 fd 为下标的对象数据,一定要记住对象 reset 完成之后,才能关闭 fd.
提前关闭 fd 会造成其它线程重新使用了这个 fd,进而两个线程同时操作同一个 poller对象,造成内存错误.
本人消耗了一下午的时候来解决这个 bug...

这儿的时序是一定要保障的,为了安全,我还在这儿加了内存屏障。

fly2best:内存屏障, 子内核中看到过，丫的从来没用过....


字符串方面操作的优化:
1.  用数字比较代替字符串比较,nginx 中也大量使用了这个技巧。
2.  不用 memset 将 buffer 置 0,只要将第一个字节置 0,然后使用安全的字符串操作函数就不可能出错。
3.  当 xbuffer_t 在扩展 buf 大小的时候,每次以 128 的粒度增加,避免频繁扩 展。(128 是经验值)
4.  将 memcpy,strlen 等函数自己实现或将代码 copy 过来然后 inline 掉, 将会极大减少函数调用开销。



效果
----
经过以上方面的优化,我们在使用 perf 来看 TWP 的运行情况来看,已经非
常理想了,占用率高的,不管是内核态还是用户态的,都是有效操作。

fly2best: perf 这个工具还不熟悉, 等我用会了, 再来整理,那个截图.


高并发下的 server 模型
======================

研究 server 模型的目的
---------------------
1.  为了适应特定的硬件体系与 OS 特点
    比如说相同的 server 模型在 SMP 体系下与 NUMA 下的表现就可能不尽相
    同,又如在 linux 下表现尚可的进程模型在 windows 下面就非常吃力。
    好的 server 模型应该从硬件和 OS 的进步发展中,得到最大化的好处。
2.  是为了实现维护成本与性能的平衡
    好的模型会在编程难度与性能之间做比较好的平衡,并且会很容易地在特定
    场景下做重心偏移。

本篇文章的讨论的背景限定在基于 SMP 体系下的 Linux 系统上的 Server。


说在前面的话
------------

关于线程和进程

在以下所述的所有模型中,进程或线程的选用,没有太本质的区别。只是一
个重一点,另一个轻量一点。本文所论述的场景中,基本上都可以互换。

在具体的使用过程中唯一要注意的是:函数重入性(线程安全),进程间通
信与线程间共享的区别。

me:我这个注意真是说到点上了.

关于这个话题

这个话题的水非常深,我在这儿也是只是结合特定场景和亲身经历分享一下
自己的心得,不可能面面俱到,更不敢保证所讲的正确性。仅仅是老老实实
把自己实践的经验说出来,不敢有半点装逼之倾向。。

me: 我还想针对这个模型写篇总结呢...., 没经验Y，要尽快搭建我的原型系统.

server模型
-----------

阻塞

单进程

fork

prefork

me:这个unp上有很好的例子.

非阻塞

perfork + 异步模型

me:muduo的实现是极好的例子.

异步”在不同的场景下,意义不尽相同。这儿所谓的异步,就是使用 IO
多路复技术,使用有限状态机轮转的事件驱动方式处理业务逻辑。状态机里面
的任何操作都必须是非阻塞的,由于 N 多请求在一个线程里面跑,所以只要
有一个点有阻塞,整个状态机制轮转会停下来,所有下在处理的任务都会受到
影响.

me: 应该来这么设计我的原型系统.

me: TWP的模式，是reactor模型，有多个event loop.
    muduo内置支持.

异步流水线
me: 这个没见过，详细了解了解.

上面提到的异步模型处理的业务相对简单,包括 web proxy,所有的业务逻辑抽象成有限状态机也不是很复杂。
但如果 server 的功能特性比较多的话,全部抽象到一个状态机,不管是实现还是维护、debug 都比较困难。
针对这种情况, 于是就引出了这儿要介绍的异步流水线架构。

如何将一个 server 中的流程和功能解耦, unix哲学给我们提供了一条异常好用的解决方案.
异步流水线:每个模块只干一件事情,把每个模块用管道连接起来!

me: 这个异步流水线，理解的不是很好... 有空再回来琢磨琢磨.

几个性能注意点
---------------
TCP_DEFER_ACCEPT
在 listen fd 上设置 TCP_DEFER_ACCEPT 后,accpet(2)和 listen fd 的行为会
发行变化。三次握手之后,应用层是感知不到,只有当有真正的用户数据到达的
时候,应用层才会感知到(阻塞的 accept 返回或 listen fd 有事件通知)。这时
accept 出来的 fd 直接进行读操作就可以了,不用再等 INPUT 事件通知了。这
样可以节省一点点资源。


accept4, socket与SOCK_NONBLOCK

在将 fd 放入 epoll 池子进行管理的时候,一定要先将 fd 用 fcntl(2)设置成非阻
塞。从 Linux 2.6.28 开始的 accept4 支持 SOCK_NOBLOCK 参数,accept 出
来的 fd 就已经是非阻塞的了。这样就可以减少一次 fcntl(2)的调用开销了。
同样 socket(2)调用从 2.6.27 开始支持 SOCK_NONBLOCK 参数了。
特别是从老的系统中迁移过来的 server,可以注意一下这两个地方,看看能不
能优化。

非事件触发 send
在 epoll 状态机中,send 操作最好是需要的时候直接调用,而不是先打开
OUTPUT 事件等回调。因为一般情况下,fd 都是可写的,只有当发送缓存区满
的情况下才打开 OUTPUT 事件等合适的机会再发送出去。这一点一般大伙儿也
都是这么实现的。

上面实现虽然效率会高些, 但是代码结构会不清晰,
在不同的地方都会出现 send 操作。
以下是我们的解决思路:
在 Server 的定时器单元中,实现一个特殊的定时器—ReadyTimer。
挂到这个timer上面的事件,会在检查超进操作时立刻被回调。
也就是说超时时间是 0。
实际上就是一个推后的回调机制,借用这个机制可以在 send 的地方把事件挂到
ReadyTimer 上,由 ReadyTimer 负责回调 send 操作(跟 OUTPUT 事件的回调
函数是一个)。这样既没有使用多余的 OUTPUT 事件搞高了效率,代码又没有冗
余。

这个跟内核中硬中断通过raise_sofirq()置位软件中断,
 do_softirq()来轮询并回调handler的思路是类似的。


gettimeofday
在 server 有很多地方需要时间,而在在比较老的系统中(不支持 vdso),
gettimeofday 是非常消耗资源的,所以在使用 gettimeofday 的时候必须克勤
克俭。虽然现在新的内核中,问题已经不是那么大了,但我们都从苦日子中过来
的,节约一点是一点。
节省的方式实际上在各个 server 中的方式大体上都是一致的,即牺牲一定的精
度换取性能。一般都是在 epoll_wait(2)后取一次,然后在整个大循环中都用这
一值作为当前时间。
由于整过程都是非阻塞的,
基本上可以保证精度在毫秒级别。
对于一般的应用场景足够了。我隐约记得 nginx 中好像也是这么处理的。

小结
-----
性能优化与业务抽象很大程度上是矛盾的两件事。
性能优化代码要往底层靠, 而业务抽象要往上层走。
所以性能优化一定要适度,做到合适我们的应用场景就好了。
为了性能,在代码中各种 hack,导致代码可读性、可维护性降低,是得不偿失的。
在性能优化和代码清晰之间做选择的时候,绝大多数时候要选择后者。
我曾经无数次想在代码里装装逼,几乎无一例外地被雷劈了!


